{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-21 19:45:43,299 - matplotlib.pyplot - DEBUG - Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from requests import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, file_name):\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        response = get(url)\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mnist(images_path: str, labels_path: str):\n",
    "    with gzip.open(labels_path, 'rb') as labelsFile:\n",
    "        labels = np.frombuffer(labelsFile.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(images_path,'rb') as imagesFile:\n",
    "        length = len(labels)\n",
    "        # Load flat 28x28 px images (784 px), and convert them to 28x28 px\n",
    "        features = np.frombuffer(imagesFile.read(), dtype=np.uint8, offset=16) \\\n",
    "                        .reshape(length, 784) \\\n",
    "                        .reshape(length, 28, 28, 1)\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-21 19:45:44,130 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): yann.lecun.com:80\n",
      "2020-04-21 19:45:44,787 - urllib3.connectionpool - DEBUG - http://yann.lecun.com:80 \"GET /exdb/mnist/train-images-idx3-ubyte.gz HTTP/1.1\" 200 9912422\n",
      "2020-04-21 19:45:46,477 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): yann.lecun.com:80\n",
      "2020-04-21 19:45:46,937 - urllib3.connectionpool - DEBUG - http://yann.lecun.com:80 \"GET /exdb/mnist/train-labels-idx1-ubyte.gz HTTP/1.1\" 200 28881\n",
      "2020-04-21 19:45:46,942 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): yann.lecun.com:80\n",
      "2020-04-21 19:45:47,318 - urllib3.connectionpool - DEBUG - http://yann.lecun.com:80 \"GET /exdb/mnist/t10k-images-idx3-ubyte.gz HTTP/1.1\" 200 1648877\n",
      "2020-04-21 19:45:48,144 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): yann.lecun.com:80\n",
      "2020-04-21 19:45:48,502 - urllib3.connectionpool - DEBUG - http://yann.lecun.com:80 \"GET /exdb/mnist/t10k-labels-idx1-ubyte.gz HTTP/1.1\" 200 4542\n"
     ]
    }
   ],
   "source": [
    "download_file('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', 'train-images-idx3-ubyte.gz')\n",
    "download_file('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n",
    "download_file('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', 't10k-images-idx3-ubyte.gz')\n",
    "download_file('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', 't10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}\n",
    "test = {}\n",
    "\n",
    "train['features'], train['labels'] = read_mnist('train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n",
    "test['features'], test['labels'] = read_mnist('t10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training images: 60000\n",
      "# of test images: 10000\n"
     ]
    }
   ],
   "source": [
    "print('# of training images:', train['features'].shape[0])\n",
    "print('# of test images:', test['features'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Pad images with 0s\n",
    "train['features']      = np.pad(train['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "test['features']       = np.pad(test['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(train['features'][0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 30, 30, 6)         60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_7 (Average (None, 15, 15, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 13, 13, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_8 (Average (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 81,194\n",
      "Trainable params: 81,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LeNet-5 as teacher\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=10, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['features'], to_categorical(train['labels'])\n",
    "X_test, y_test = test['features'], to_categorical(test['labels'])\n",
    "\n",
    "train_generator = ImageDataGenerator().flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "test_generator = ImageDataGenerator().flow(X_test, y_test, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training images: 60000\n",
      "# of validation images: 10000\n",
      "Epoch 1/10\n",
      "468/468 [==============================] - 31s 66ms/step - loss: 0.3732 - accuracy: 0.9181 - val_loss: 0.0935 - val_accuracy: 0.9768\n",
      "Epoch 2/10\n",
      "468/468 [==============================] - 31s 67ms/step - loss: 0.0700 - accuracy: 0.9785 - val_loss: 0.0767 - val_accuracy: 0.9826\n",
      "Epoch 3/10\n",
      "468/468 [==============================] - 30s 65ms/step - loss: 0.0479 - accuracy: 0.9847 - val_loss: 0.0499 - val_accuracy: 0.9848\n",
      "Epoch 4/10\n",
      "468/468 [==============================] - 30s 65ms/step - loss: 0.0393 - accuracy: 0.9872 - val_loss: 0.0291 - val_accuracy: 0.9888\n",
      "Epoch 5/10\n",
      "468/468 [==============================] - 30s 65ms/step - loss: 0.0311 - accuracy: 0.9900 - val_loss: 0.0110 - val_accuracy: 0.9862\n",
      "Epoch 6/10\n",
      "468/468 [==============================] - 30s 65ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.0374 - val_accuracy: 0.9887\n",
      "Epoch 7/10\n",
      "468/468 [==============================] - 30s 65ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.0228 - val_accuracy: 0.9882\n",
      "Epoch 8/10\n",
      "468/468 [==============================] - 30s 65ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0337 - val_accuracy: 0.9844\n",
      "Epoch 9/10\n",
      "468/468 [==============================] - 30s 65ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.0063 - val_accuracy: 0.9862\n",
      "Epoch 10/10\n",
      "468/468 [==============================] - 30s 65ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.0023 - val_accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a661a8650>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('# of training images:', train['features'].shape[0])\n",
    "print('# of validation images:', test['features'].shape[0])\n",
    "\n",
    "steps_per_epoch = X_train.shape[0]//BATCH_SIZE\n",
    "test_steps = X_test.shape[0]//BATCH_SIZE\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=EPOCHS, \n",
    "                    validation_data=test_generator, validation_steps=test_steps, \n",
    "                    shuffle=True, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_20 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 32)                32800     \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 33,130\n",
      "Trainable params: 33,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "student = Sequential()\n",
    "student.add(Flatten(input_shape=(32,32,1)))\n",
    "student.add(Dense(32, activation='relu'))\n",
    "student.add(Dropout(0.2))\n",
    "student.add(Dense(nb_classes))\n",
    "student.add(Activation('softmax'))\n",
    "\n",
    "student.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 1\n",
    "\n",
    "teacher_WO_Softmax = Model(model.input, model.get_layer('dense_40').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/(np.exp(x).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_train_logits = teacher_WO_Softmax.predict(X_train)\n",
    "teacher_test_logits = teacher_WO_Softmax.predict(X_test) \n",
    "train_logits_T = teacher_train_logits/temp\n",
    "test_logits_T = teacher_test_logits / temp \n",
    "\n",
    "Y_train_soft = softmax(train_logits_T)\n",
    "Y_test_soft = softmax(test_logits_T)\n",
    "\n",
    "Y_train_new = np.concatenate([Y_train, Y_train_soft], axis=1)\n",
    "Y_test_new =  np.concatenate([Y_test, Y_test_soft], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 20)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 20)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 32, 32, 1)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.4228697e-06, 1.4228697e-06,\n",
       "       1.4228697e-06, 1.4776838e-06, 1.4228697e-06, 3.7242855e-06,\n",
       "       1.4228697e-06, 1.4228697e-06, 1.4228707e-06, 1.4228697e-06],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "flatten_20_input (InputLayer)   (None, 32, 32, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 1024)         0           flatten_20_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 32)           32800       flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 32)           0           dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 10)           330         dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 10)           0           dense_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 10)           0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 10)           0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 10)           0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 20)           0           activation_29[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 33,130\n",
      "Trainable params: 33,130\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "student.layers.pop()\n",
    "\n",
    "\n",
    "logits = student.layers[-1].output \n",
    "probs = Activation('softmax')(logits)\n",
    "\n",
    "logits_T = Lambda(lambda x: x / temp)(logits)\n",
    "probs_T = Activation('softmax')(logits_T)\n",
    "\n",
    "output = concatenate([probs, probs_T])\n",
    "\n",
    "student = Model(student.input, output)\n",
    "\n",
    "student.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knowledge_distillation_loss(y_true, y_pred, alpha):\n",
    "    y_true, y_true_softs = y_true[: , :nb_classes], y_true[: , nb_classes:]\n",
    "    \n",
    "    y_pred, y_pred_softs = y_pred[: , :nb_classes], y_pred[: , nb_classes:]\n",
    "    \n",
    "    loss = alpha*logloss(y_true,y_pred) + logloss(y_true_softs, y_pred_softs)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def acc(y_true, y_pred):\n",
    "    y_true = y_true[:, :nb_classes]\n",
    "    y_pred = y_pred[:, :nb_classes]\n",
    "    return categorical_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "student.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 2.7879 - accuracy: 0.3661 - val_loss: 2.5964 - val_accuracy: 0.5580\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 2.6037 - accuracy: 0.5503 - val_loss: 2.4750 - val_accuracy: 0.6795\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 2.5111 - accuracy: 0.6430 - val_loss: 2.4457 - val_accuracy: 0.7087\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 2.4820 - accuracy: 0.6721 - val_loss: 2.4416 - val_accuracy: 0.7126\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 2.4753 - accuracy: 0.6789 - val_loss: 2.4305 - val_accuracy: 0.7242\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 2.4283 - accuracy: 0.7259 - val_loss: 2.3580 - val_accuracy: 0.7966\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 2.3891 - accuracy: 0.7652 - val_loss: 2.3445 - val_accuracy: 0.8100\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 2.3774 - accuracy: 0.7768 - val_loss: 2.3383 - val_accuracy: 0.8162\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 2.3740 - accuracy: 0.7803 - val_loss: 2.3332 - val_accuracy: 0.8213\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 2.3660 - accuracy: 0.7882 - val_loss: 2.3277 - val_accuracy: 0.8267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a8802c690>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.fit(X_train, Y_train_new,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
